{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4d7c115",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T22:13:24.924999Z",
     "start_time": "2022-06-19T22:13:21.567849Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from pandas import DataFrame\n",
    "#Parallelism\n",
    "import joblib\n",
    "from joblib import Parallel, delayed,parallel_backend\n",
    "import datetime\n",
    "\n",
    "# Preprocessing, modelling and evaluating\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,mean_squared_error, mean_absolute_error\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755fe410",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a3e95a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T22:23:35.169198Z",
     "start_time": "2022-06-19T22:23:35.089163Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocessing, modelling and evaluating\n",
    "from sklearn.preprocessing import MaxAbsScaler,StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "## Hyperopt modules\n",
    "# from hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\n",
    "# from functools import partial\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "378ab3a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T22:24:35.484452Z",
     "start_time": "2022-06-19T22:24:35.471434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_transaction.csv', '._test_transaction.csv', 'train_identity.csv', '._train_identity.csv', 'test_identity.csv', '._test_identity.csv', 'sample_submission.csv', '._sample_submission.csv', 'train_transaction.csv', '._train_transaction.csv', 'train_merged.csv', 'test_merged.csv']\n"
     ]
    }
   ],
   "source": [
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../../data\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68a0eee2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T22:32:55.319521Z",
     "start_time": "2022-06-19T22:31:57.848213Z"
    }
   },
   "outputs": [],
   "source": [
    "base_path = '../../data/'\n",
    "\n",
    "train_id = pd.read_csv(base_path + 'train_identity.csv')\n",
    "train_trans = pd.read_csv(base_path + 'train_transaction.csv')\n",
    "test_id = pd.read_csv(base_path + 'test_identity.csv')\n",
    "test_trans = pd.read_csv(base_path + 'test_transaction.csv')\n",
    "# submission = pd.read_csv(base_path + 'sample_submission.csv')\n",
    "\n",
    "df_trans = pd.read_csv(base_path + 'train_transaction.csv', index_col='TransactionID')\n",
    "df_test_trans = pd.read_csv(base_path + 'test_transaction.csv', index_col='TransactionID')\n",
    "\n",
    "df_id = pd.read_csv(base_path + 'train_identity.csv', index_col='TransactionID')\n",
    "df_test_id = pd.read_csv(base_path + 'test_identity.csv', index_col='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e56af479",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T22:40:55.885037Z",
     "start_time": "2022-06-19T22:40:55.869977Z"
    }
   },
   "outputs": [],
   "source": [
    "# column명 변경\n",
    "df_test_id.columns = [i.replace('-','_') for i in df_test_id.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90321e61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T22:41:11.867313Z",
     "start_time": "2022-06-19T22:41:10.663961Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_trans.merge(df_id, how='left', left_index=True, right_index=True)\n",
    "df_test = df_test_trans.merge(df_test_id, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2dce2496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T22:42:01.527496Z",
     "start_time": "2022-06-19T22:41:12.969460Z"
    }
   },
   "outputs": [],
   "source": [
    "## Function to reduce the DF size\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "many_null_cols = [col for col in df_train.columns if df_train[col].isnull().sum() / df_train.shape[0] > 0.9]\n",
    "many_null_cols_test = [col for col in df_test.columns if df_test[col].isnull().sum() / df_test.shape[0] > 0.9]\n",
    "\n",
    "cols_to_drop = list(set(many_null_cols + many_null_cols_test))\n",
    "len(cols_to_drop)\n",
    "\n",
    "df_train = df_train.drop(cols_to_drop, axis=1)\n",
    "df_test = df_test.drop(cols_to_drop, axis=1)\n",
    "\n",
    "df_train = df_train.fillna(-999)\n",
    "df_test = df_test.fillna(-999) \n",
    "\n",
    "for f in df_train.columns:\n",
    "    if df_train[f].dtype=='object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(df_train[f].values) + list(df_test[f].values))\n",
    "        df_train[f] = lbl.transform(list(df_train[f].values))\n",
    "        df_test[f] = lbl.transform(list(df_test[f].values))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43118049",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-19T22:53:49.542455Z",
     "start_time": "2022-06-19T22:43:46.923721Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Spark\\AppData\\Local\\Temp\\ipykernel_8132\\1201443597.py:7: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 283 columns to remove.\n",
      "Mem. usage decreased to 176.28 Mb (68.2% reduction)\n",
      "Mem. usage decreased to 158.98 Mb (66.6% reduction)\n",
      "********************** XGBoost GridSearch CV abou to starts ***************************\n",
      "2022-06-20 07:47:12.411146\n",
      "\n",
      "------------ fit method starts ---------------\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV] END ........................................max_depth=9; total time=  47.7s\n",
      "[CV] END ........................................max_depth=9; total time= 2.5min\n",
      "\n",
      "------------ fit method starts ---------------\n",
      "\n",
      "********************** XGBoost GridSearch CV ends ***************************\n",
      "2022-06-20 07:53:47.872665\n",
      "\n",
      "Best score: 0.882\n",
      "Best parameters set:\n",
      "\tmax_depth: 9\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.98\n",
    "    \n",
    "# Absolute value correlation matrix\n",
    "corr_matrix = df_train[df_train['isFraud'].notnull()].corr().abs()\n",
    "\n",
    "# Getting the upper triangle of correlations\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Select columns with correlations above threshold\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "print('There are %d columns to remove.' % (len(to_drop)))\n",
    "df_train = df_train.drop(columns = to_drop)\n",
    "df_test = df_test.drop(columns = to_drop)\n",
    "\n",
    "\n",
    "X_train = df_train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT'], axis=1)\n",
    "y_train = df_train.sort_values('TransactionDT')['isFraud']\n",
    "X_test = df_test.sort_values('TransactionDT').drop(['TransactionDT'], axis=1)\n",
    "\n",
    "df_test = df_test[[\"TransactionDT\"]]\n",
    "\n",
    "features = list(df_train.columns[1:])  #la colonne 0 est le quote_conversionflag  \n",
    "'''\n",
    "parameters = {\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05],\n",
    "              'max_depth': [9],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.9],\n",
    "              'colsample_bytree': [1.0],\n",
    "              'n_estimators': [500], #number of trees, change it to 1000 for better results\n",
    "              'missing':[-999],\n",
    "              'random_state': [2019],\n",
    "              'reg_alpha':  [0.01],\n",
    "              'reg_lambda': [0.3],\n",
    "              'gamma': [0.1],\n",
    "              'num_leaves': [20],       \n",
    "              'min_child_samples':  [10, 80, 3],\n",
    "              'feature_fraction': [ 0.6],\n",
    "              'bagging_fraction': [ 0.7]\n",
    "            }\n",
    "'''\n",
    "parameters = {\n",
    "                'max_depth': [9]\n",
    "\n",
    "            }\n",
    "X_train = reduce_mem_usage(X_train)\n",
    "X_test = reduce_mem_usage(X_test)\n",
    "\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=2)\n",
    "#==============================================XGBClassifier=============================\n",
    "model = xgb.XGBClassifier()\n",
    "clf = GridSearchCV(model, parameters, \n",
    "                cv=tscv, \n",
    "                scoring='roc_auc',\n",
    "                verbose=2, refit=True)\n",
    "print('********************** XGBoost GridSearch CV abou to starts ***************************')\n",
    "print(datetime.datetime.now())\n",
    "print()\n",
    "print('------------ fit method starts ---------------')\n",
    "\n",
    "#Parallel(n_jobs=7)\n",
    "#(delayed(\n",
    "clf.fit(X_train, y_train)\n",
    "#))\n",
    "print()\n",
    "print('------------ fit method starts ---------------')\n",
    "print()\n",
    "print('********************** XGBoost GridSearch CV ends ***************************')\n",
    "print(datetime.datetime.now())\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % clf.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters=clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "test_probs = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# sample = pd.read_csv('../input/sample_submission.csv')\n",
    "# sample.isFraud = test_probs\n",
    "# sample.to_csv(\"xgboost_best_parameter_submission.csv\", index=False)\n",
    "#=============================KNeighborsClassifier=============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe8a905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
